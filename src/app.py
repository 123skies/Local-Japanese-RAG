# â–¼â–¼â–¼â–¼â–¼ ãƒ¢ãƒ³ã‚­ãƒ¼ãƒ‘ãƒƒãƒ â–¼â–¼â–¼â–¼â–¼
import os
import sys

# ã€é‡è¦ã€‘Streamlitã¨PyTorchã®ç«¶åˆã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãƒ‘ãƒƒãƒ
# StreamlitãŒ torch.classes ã‚’ãƒ•ã‚©ãƒ«ãƒ€ã¨ã—ã¦ã‚¹ã‚­ãƒ£ãƒ³ã—ã‚ˆã†ã¨ã—ã¦ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã™ã‚‹ã®ã‚’é˜²ãã¾ã™ã€‚
# ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆengineãªã©ï¼‰ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹å‰ã«ã€ã“ã“ã§ç¢ºå®Ÿã«ç„¡åŠ¹åŒ–ã—ã¾ã™ã€‚
import torch
if hasattr(torch, 'classes'):
    torch.classes.__path__ = []

# â–²â–²â–²â–²â–² ã“ã“ã¾ã§ â–²â–²â–²â–²â–²

# project_root/src/app.py
import streamlit as st
import os
import time
import datetime
import json
import tiktoken
from modules import highlight
import logging
import logging.handlers
from engine import ScholarScopeEngine
from modules.date_standardizer import DateStandardizer
from pathlib import Path
import re
import argparse

# --- ãƒ­ã‚¬ãƒ¼ã®å–å¾—ã®ã¿ã‚’å…ˆã«è¡Œã† ---
logger = logging.getLogger('scholarscope_lite')

def setup_logging(engine: ScholarScopeEngine):
    if logger.hasHandlers():
        return

    log_file_path = engine.log_file_path  # ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰æ­£ã—ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å–å¾—

    # --- config.tomlã‹ã‚‰ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’å–å¾— ---
    console_level_str = engine.console_log_level
    file_level_str = engine.file_log_level
    # æ–‡å­—åˆ—ã‚’loggingãƒ¬ãƒ™ãƒ«ã«å¤‰æ› (ä¸æ­£ãªå€¤ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨)
    console_level = getattr(logging, console_level_str, logging.INFO)
    file_level = getattr(logging, file_level_str, logging.WARNING)

    logger.propagate = False
    # ãƒ­ã‚¬ãƒ¼è‡ªä½“ã®ãƒ¬ãƒ™ãƒ«ã¯æœ€ã‚‚ä½ã„ãƒ¬ãƒ™ãƒ«ã«è¨­å®šã—ã€ãƒãƒ³ãƒ‰ãƒ©ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹
    logger.setLevel(min(console_level, file_level, logging.INFO))
    file_handler = logging.handlers.RotatingFileHandler(
        log_file_path, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8'
    )
    file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(module)s.%(funcName)s:%(lineno)d - %(message)s')
    file_handler.setFormatter(file_formatter)
    file_handler.setLevel(file_level)
    logger.addHandler(file_handler)

    stream_handler = logging.StreamHandler()
    stream_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    stream_handler.setFormatter(stream_formatter)
    stream_handler.setLevel(console_level)
    logger.addHandler(stream_handler)

    logger.info("--- Application Logger Initialized (PID: %s) ---", os.getpid())
    logger.info(f"ãƒ­ã‚°ã¯ '{log_file_path}' ã«å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚(ãƒ•ã‚¡ã‚¤ãƒ«ãƒ¬ãƒ™ãƒ«: {file_level_str})")
    logger.info(f"ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {console_level_str}")

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ScholarScope", layout="wide")

# ### å¤‰æ›´ ###: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å‰Šé™¤
# QA_SYSTEM_PROMPT = """..."""
# QGEN_SYSTEM_PROMPT = """..."""

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
def initialize_session_state():
    if 'initialized' not in st.session_state:
        default_session_state = {
            'engine': None,
            'initialized': False,
            'uploaded_file_info_list': [],
            'executed_and_query_for_highlight': "",
            'executed_bm25_query_for_highlight': "",
            'executed_semantic_query_for_highlight': "",
            'last_executed_must_keywords': "",
            'last_executed_semantic_query': "",
            'last_executed_full_text_query': "",
            'last_executed_doc_name_filter': "",
            'and_search_results': [],
            'keyword_search_results': [],
            'vector_search_results': [],
            'reranked_search_results': [],
            'max_context_tokens_for_prompt': 7000, # ã‚ã¨ã§engineã‹ã‚‰ä¸Šæ›¸ã
            'show_ai_question_pane': True,
            'search_result_meta': {}, # è¿½åŠ : æ¤œç´¢çµæœã®ãƒ¡ã‚¿æƒ…å ±ï¼ˆhas_moreãªã©ï¼‰
            'current_ai_question_text': "",
            'initialization_status': "pending",
            'rebuild_decision_made': False,
            'user_chose_to_rebuild': None,
            'user_chose_to_incrementally_update': None,
            'contexts_for_prompt_docs_precomputed': [],
            'contexts_string_precomputed': "",
            'current_total_tokens_precomputed': 0,
            'last_used_max_context_tokens_for_prompt_in_contexts_string': 7000, # ã‚ã¨ã§engineã‹ã‚‰ä¸Šæ›¸ã
            'last_query_for_precompute_v2': None,
            'prompt_display_text_right_pane': "",
            'current_prompt_type': None,
            'llm_response': "",
            'user_prompt_for_ollama': "",
            'citation_map': {},
            'is_streaming': False,
            'ui_state': 'idle',  # idle, streaming_answer, getting_citations, done
            'prompt_citation_map': {},
            'clean_answer': "",
            'final_answer': "",
            'contexts_for_citation': "",
            'system_prompt_for_ollama': "",
            'skip_rerank': False,
            'is_deep_search_mode': False,
            'search_request': None,
            'executed_optimized_bm25_query': None,
            'last_search_duration': 0.0,
            'is_searching': False,
            'search_was_cancelled': False, # è¿½åŠ : æ¤œç´¢ä¸­æ–­ãƒ•ãƒ©ã‚°
        }
        for key, value in default_session_state.items():
            if key not in st.session_state: st.session_state[key] = value

initialize_session_state()

def reset_application_state():
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®çŠ¶æ…‹ã‚’åˆæœŸåŒ–ï¼ˆå…¥åŠ›ã‚¯ãƒªã‚¢ï¼†çµæœã‚¯ãƒªã‚¢ï¼‰"""
    # æ¤œç´¢çµæœã®ã‚¯ãƒªã‚¢
    st.session_state.and_search_results = []
    st.session_state.keyword_search_results = []
    st.session_state.vector_search_results = []
    st.session_state.reranked_search_results = []
    st.session_state.search_was_cancelled = False
    st.session_state.search_result_meta = {}
    st.session_state.llm_response = ""
    st.session_state.clean_answer = ""
    st.session_state.final_answer = ""
    st.session_state.prompt_display_text_right_pane = ""
    
    # å±¥æ­´å¤‰æ•°ã®ã‚¯ãƒªã‚¢
    st.session_state.last_executed_must_keywords = ""
    st.session_state.last_executed_semantic_query = ""
    st.session_state.last_executed_full_text_query = ""
    st.session_state.last_executed_doc_name_filter = ""
    st.session_state.current_ai_question_text = ""
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã®ã‚¯ãƒªã‚¢ï¼ˆsession_stateã®ã‚­ãƒ¼çµŒç”±ï¼‰
    keys_to_clear = ["input_full_text", "input_doc_name_filter", "input_semantic_query"]
    for k in keys_to_clear:
        if k in st.session_state:
            st.session_state[k] = ""
    
    # UIçŠ¶æ…‹ã®ãƒªã‚»ãƒƒãƒˆ
    st.session_state.reranked_results_expanded_state = None
    st.session_state.and_results_expanded_state = None
    st.session_state.bm25_results_expanded_state = None
    st.session_state.vector_results_expanded_state = None
    st.session_state.show_ai_question_pane = True
    st.session_state.ui_state = 'idle'

    # æœ€é©åŒ–ãƒ»ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã®ã‚¯ãƒªã‚¢
    st.session_state.executed_optimized_bm25_query = None
    st.session_state.executed_rerank_query = None
    st.session_state.executed_bm25_query_for_highlight = ""
    st.session_state.executed_semantic_query_for_highlight = ""
    st.session_state.executed_and_query_for_highlight = ""

    logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã«ã‚ˆã‚Šæ¡ä»¶ã¨çµæœã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")

def save_search_history(history_entry: dict):
    search_history_file = st.session_state.engine.search_history_path
    try:
        with open(search_history_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(history_entry, ensure_ascii=False) + '\n')
    except Exception as e:
        logger.error(f"æ¤œç´¢å±¥æ­´ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)

def render_right_column():
    with right_column:
        col_header_right, col_close_btn_right = st.columns([0.9, 0.1])
        with col_header_right: st.subheader("æ¤œç´¢çµæœã‚’ä½¿ã£ãŸAIåˆ†æ")
        with col_close_btn_right:
            if st.button("âœ–ï¸", key="close_ai_pane_button_right_key", help="AIè³ªå•ãƒ‘ãƒãƒ«ã‚’éš ã™", use_container_width=True):
                st.session_state.show_ai_question_pane = False; logger.debug("AIè³ªå•ãƒ‘ãƒãƒ«ã‚’éè¡¨ç¤ºã«ã—ã¾ã—ãŸã€‚"); st.rerun()

        # è³ªå•å…¥åŠ›ã‚¨ãƒªã‚¢
        edited_question = st.text_area(
            "è³ªå•ãƒ»é–¢å¿ƒäº‹ (ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨):",
            value=st.session_state.current_ai_question_text,
            key="ai_question_text_area_right_key_unique",
            height=150,
            help="ã€Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ã§ä½¿ç”¨ã—ã¾ã™ã€‚æ¤œç´¢çµæœã‚’å…ƒã«ã€ã“ã“ã«å…¥åŠ›ã—ãŸè³ªå•ã«æ²¿ã£ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’AIãŒç”Ÿæˆã—ã¾ã™ã€‚"
        )
        if edited_question != st.session_state.current_ai_question_text:
            logger.debug(f"AIè³ªå•æ–‡ãŒç·¨é›†ã•ã‚Œã¾ã—ãŸã€‚æ–°: '{edited_question[:50]}...'")
        st.session_state.current_ai_question_text = edited_question

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³
        any_search_results = st.session_state.reranked_search_results or \
                             st.session_state.and_search_results or \
                             st.session_state.keyword_search_results or \
                             st.session_state.vector_search_results
        action_buttons_enabled = any_search_results and st.session_state.current_ai_question_text.strip()

        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ¤– ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ", key="generate_ai_answer_button", help="æ¤œç´¢çµæœã¨ä¸Šã®è³ªå•æ–‡ã‚’å…ƒã«ã€è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚", disabled=not action_buttons_enabled, use_container_width=True, type="primary"):
                logger.info("ã€Œãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸã€‚")
                st.session_state.ui_state = 'streaming_answer'
                st.session_state.clean_answer = ""
                st.session_state.final_answer = ""
                st.session_state.llm_response = "" # æ—§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¯ãƒªã‚¢

                with st.spinner("AIã¸ã®è³ªå•æº–å‚™ä¸­..."):
                    # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚¹ã‚­ãƒƒãƒ—æ™‚ã¯bm25ã¨vectorã®çµæœã‚‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã«å«ã‚ã‚‹
                    search_results_for_prompt = {
                        "reranked": st.session_state.reranked_search_results,
                        "and": st.session_state.and_search_results,
                        "bm25": st.session_state.keyword_search_results,
                        "vector": st.session_state.vector_search_results
                    }
                    prompt_data = st.session_state.engine.generate_prompt_for_llm(
                        search_results_dict=search_results_for_prompt,
                        question_text=st.session_state.current_ai_question_text,
                        max_tokens=st.session_state.max_context_tokens_for_prompt
                    )
                    st.session_state.contexts_for_citation = prompt_data["contexts_string"]
                    st.session_state.prompt_citation_map = prompt_data["citation_map"]
                    user_prompt_content = f"""**æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:**\n{prompt_data["contexts_string"]}\n\n---\n**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãƒ»é–¢å¿ƒ:**\n{st.session_state.current_ai_question_text}"""
                    st.session_state.user_prompt_for_ollama = user_prompt_content
                    # system_promptã¯ã‚¨ãƒ³ã‚¸ãƒ³å´ã§å›ºå®šã•ã‚Œã‚‹ãŸã‚ã€ã“ã“ã§ã¯è¨­å®šä¸è¦
                    st.session_state.prompt_display_text_right_pane = f"{st.session_state.engine.qa_system_prompt}\n---\n{user_prompt_content}"

                st.rerun()

        with col2:
            if st.button("ğŸ” è«–ç‚¹/ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡º", key="extract_points_button", help="æ¤œç´¢çµæœã‚’å…ƒã«ã€èª¿æŸ»å¯èƒ½ãªæ–°ãŸãªè«–ç‚¹ã‚„ãƒˆãƒ”ãƒƒã‚¯ã‚’AIãŒææ¡ˆã—ã¾ã™ã€‚ä¸Šã®è³ªå•æ–‡ã¯ä½¿ç”¨ã—ã¾ã›ã‚“ã€‚", disabled=not any_search_results, use_container_width=True):
                logger.info("ã€Œè«–ç‚¹/ãƒˆãƒ”ãƒƒã‚¯ã‚’æŠ½å‡ºã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸã€‚")
                st.session_state.ui_state = 'idle'
                st.session_state.llm_response = ""

                with st.spinner("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆä¸­..."):
                    search_results_for_prompt = {
                        "reranked": st.session_state.reranked_search_results,
                        "and": st.session_state.and_search_results,
                        "bm25": st.session_state.keyword_search_results,
                        "vector": st.session_state.vector_search_results
                    }
                    prompt_data = st.session_state.engine.generate_prompt_for_llm(
                        search_results_dict=search_results_for_prompt, question_text="",
                        max_tokens=st.session_state.max_context_tokens_for_prompt
                    )
                st.session_state.user_prompt_for_ollama = f"""**æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:**\n{prompt_data["contexts_string"]}"""
                st.session_state.system_prompt_for_ollama = st.session_state.engine.qgen_system_prompt
                st.session_state.prompt_display_text_right_pane = f"{st.session_state.system_prompt_for_ollama}\n---\n{st.session_state.user_prompt_for_ollama}"
                st.session_state.is_streaming = True
                st.rerun()

        # --- è©³ç´°è¨­å®š Expander ---
        with st.expander("ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°"):
            st.text_area(
                "ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå¤–éƒ¨LLMã¸ã®ã‚³ãƒ”ãƒ¼ç”¨ï¼‰:",
                value=st.session_state.prompt_display_text_right_pane,
                height=300, key="prompt_display_text_area_right_pane_key",
                help="ã“ã“ã«ç”Ÿæˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å¤–éƒ¨LLMã§è©¦ã™å ´åˆã¯ã“ã“ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã—ã¦ãã ã•ã„ã€‚",
            )

            if st.button("å…¨æ¤œç´¢çµæœã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆ", key="regenerate_prompt_with_all_contexts_button", help="ç¾åœ¨è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹å…¨ã¦ã®æ¤œç´¢çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦åˆ©ç”¨ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã—ã¾ã™ã€‚"):
                logger.info("ã€Œå…¨æ¤œç´¢çµæœã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å†ç”Ÿæˆã€ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã¾ã—ãŸã€‚")
                with st.spinner("å…¨æ¤œç´¢çµæœã‹ã‚‰ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆä¸­..."):
                    all_search_results_for_prompt = {
                        "reranked": st.session_state.reranked_search_results,
                        "and": st.session_state.and_search_results,
                        "bm25": st.session_state.keyword_search_results,
                        "vector": st.session_state.vector_search_results
                    }
                    all_contexts_string, _ = st.session_state.engine.get_all_deduplicated_contexts_string(all_search_results_for_prompt)
                    user_prompt_content = f"""**æä¾›ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:**\n{all_contexts_string}\n\n---\n**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãƒ»é–¢å¿ƒ:**\n{st.session_state.current_ai_question_text}"""
                    # å¤–éƒ¨LLMç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹
                    system_prompt_for_all_contexts = st.session_state.engine.qa_system_prompt_for_all_contexts
                    st.session_state.prompt_display_text_right_pane = f"{system_prompt_for_all_contexts}\n---\n{user_prompt_content}"
                st.rerun()

        with st.expander("é«˜åº¦ãªè¨­å®š"):
            def update_max_context_tokens():
                st.session_state.max_context_tokens_for_prompt = st.session_state.max_context_tokens_for_prompt_input_key
                logger.info(f"æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³æ•°ãŒUIã‹ã‚‰å¤‰æ›´ã•ã‚Œã¾ã—ãŸã€‚æ–°: {st.session_state.max_context_tokens_for_prompt}")
            st.number_input(
                "æœ€å¤§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³æ•°:", min_value=500, max_value=30000,
                value=st.session_state.max_context_tokens_for_prompt,
                key="max_context_tokens_for_prompt_input_key", step=100,
                help="AIã¸ã®è³ªå•æ™‚ã«å«ã‚ã‚‹ã“ã¨ãŒã§ãã‚‹æ¤œç´¢çµæœã®æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ã™ã€‚",
                on_change=update_max_context_tokens
            )

        # --- ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã‚¨ãƒªã‚¢ (2æ®µéšãƒ—ãƒ­ã‚»ã‚¹å¯¾å¿œ) ---
        if st.session_state.ui_state != 'idle':
            st.markdown("---")
            if st.session_state.ui_state == 'streaming_answer':
                # ç”Ÿæˆä¸­æ–­ãƒœã‚¿ãƒ³ã‚’ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã‚ˆã‚Šå…ˆã«é…ç½®ï¼ˆä½ç½®å›ºå®šã®ãŸã‚ï¼‰
                if st.button("â¹ï¸ ç”Ÿæˆã‚’ã‚¹ãƒˆãƒƒãƒ—", key="stop_generation_btn", type="primary"):
                    st.session_state.ui_state = 'idle'
                    st.rerun()
            # å…è²¬äº‹é …ã®è¡¨ç¤º
            st.caption("âš ï¸ **AIã«ã‚ˆã‚‹ç”Ÿæˆçµæœã¯ä¸æ­£ç¢ºãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚ã‚ãã¾ã§èª¿æŸ»ã®è£œåŠ©ã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„ã€‚**")
            # è³ªå•ãƒ»é–¢å¿ƒäº‹ã‚’è¡¨ç¤º
            st.markdown(f"##### ã€è³ªå•ãƒ»é–¢å¿ƒäº‹ã€‘ {st.session_state.current_ai_question_text}")

            # ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤ºç”¨ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã‚’ãƒœã‚¿ãƒ³ã®å¾Œã«ä½œæˆ
            answer_placeholder = st.empty()

            if st.session_state.ui_state == 'streaming_answer':
                with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                    response_generator = st.session_state.engine.stream_clean_answer(
                        user_prompt=st.session_state.user_prompt_for_ollama
                    )
                    st.session_state.clean_answer = answer_placeholder.write_stream(response_generator)

                # æ—¥ä»˜è¡¨è¨˜ã®çµ±ä¸€å‡¦ç† (å’Œæš¦ãƒ»è¥¿æš¦ã®è£œå®Œ)
                with st.spinner("æ—¥ä»˜è¡¨è¨˜ã‚’çµ±ä¸€ã—ã¦ã„ã¾ã™..."):
                    try:
                        date_converter = DateStandardizer()
                        st.session_state.clean_answer = date_converter.process_text(st.session_state.clean_answer)
                    except Exception as e:
                        logger.error(f"æ—¥ä»˜æ­£è¦åŒ–å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)

                st.session_state.ui_state = 'getting_citations'
                st.rerun()

            if st.session_state.ui_state == 'getting_citations':
                answer_placeholder.markdown(st.session_state.clean_answer, unsafe_allow_html=True)
                with st.spinner("å‡ºå…¸ã‚’æ¤œè¨¼ä¸­ã§ã™..."):
                    llm_citation_map = st.session_state.engine.get_citation_map_from_answer(
                        answer_text=st.session_state.clean_answer,
                        contexts_string=st.session_state.contexts_for_citation
                    )

                # ç®‡æ¡æ›¸ãã«å‡ºå…¸ã‚’ä»˜ä¸ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
                final_answer_parts = []
                lines = st.session_state.clean_answer.strip().split('\n')
                bullet_pattern = re.compile(r"^(\s*([\*\-]|(?:\d+\.))\s+)")
                header_pattern = re.compile(r"^\s*ã€.*?ã€‘")
                item_counter = 1

                for line in lines:
                    stripped_line = line.strip()
                    if not stripped_line:
                        final_answer_parts.append("") # ç©ºè¡Œã‚’ç¶­æŒ
                        continue

                    if header_pattern.match(stripped_line):
                        final_answer_parts.append(line)
                        continue

                    match = bullet_pattern.match(line)
                    if match:
                        item_key = f"A{item_counter}"
                        context_indices = llm_citation_map.get(item_key, [])
                        citation_str = ""

                        # LLMãŒã€Œæƒ…å ±ã®ä¸åœ¨(0)ã€ã¨åˆ¤å®šã—ãŸå ´åˆ
                        if 0 in context_indices:
                            citation_str = ""
                        
                        # LLMãŒæ ¹æ‹ ã‚’è¦‹ã¤ã‘ã‚‰ã‚Œãªã‹ã£ãŸå ´åˆï¼ˆç©ºãƒªã‚¹ãƒˆï¼‰
                        elif not context_indices:
                            citation_str = " **[ä¸æ˜ãªå‡ºå…¸]**"
                        
                        # é€šå¸¸ã®å‡ºå…¸ãŒã‚ã‚‹å ´åˆ
                        else:
                            show_numbers = st.session_state.engine.show_citation_context_numbers
                            if show_numbers:
                                citations = []
                                for idx in sorted(context_indices):
                                    filename = st.session_state.prompt_citation_map.get(idx, "ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«")
                                    citations.append(f"{idx}: {filename}")
                                citation_str = f" **[{', '.join(citations)}]**"
                            else:
                                # ç•ªå·ãªã— (ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã€é‡è¤‡æ’é™¤)
                                filenames = set()
                                for idx in sorted(context_indices):
                                    filename = st.session_state.prompt_citation_map.get(idx, "ä¸æ˜ãªãƒ•ã‚¡ã‚¤ãƒ«")
                                    filenames.add(filename)
                                citation_str = f" **[{', '.join(sorted(list(filenames)))}]**"

                        final_answer_parts.append(line.rstrip() + citation_str)
                        item_counter += 1
                    else:
                        final_answer_parts.append(line)

                st.session_state.final_answer = "\n".join(final_answer_parts)
                st.session_state.ui_state = 'done'
                st.rerun()

            if st.session_state.ui_state == 'done':
                answer_placeholder.markdown(st.session_state.final_answer, unsafe_allow_html=True)
                
                # --- AIãƒ¬ãƒãƒ¼ãƒˆãƒ­ã‚°ä¿å­˜ (è‡ªå‹•) ---
                report_log_data = {
                    "timestamp": datetime.datetime.now().isoformat(),
                    "query_semantic": st.session_state.current_ai_question_text,
                    "query_keywords": st.session_state.last_executed_must_keywords, # æ¤œç´¢æ™‚ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                    "search_query_semantic": st.session_state.last_executed_semantic_query, # æ¤œç´¢æ™‚ã®æ„å‘³ã‚¯ã‚¨ãƒª
                    "settings": {
                        "deep_search": st.session_state.is_deep_search_mode,
                        "skip_rerank": st.session_state.skip_rerank
                    },
                    "final_answer": st.session_state.final_answer,
                    "citation_contexts": list(st.session_state.prompt_citation_map.values())
                }
                st.session_state.engine.save_ai_report(report_log_data)
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                timestamp_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
                report_filename = f"report_{timestamp_str}.txt"
                report_content = f"è³ªå•ãƒ»é–¢å¿ƒäº‹:\n{st.session_state.current_ai_question_text}\n\nAIã«ã‚ˆã‚‹ãƒ¬ãƒãƒ¼ãƒˆ:\n{st.session_state.final_answer}"
                
                st.download_button(
                    label="ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=report_content,
                    file_name=report_filename,
                    mime="text/plain",
                    key="download_report_button"
                )

                with st.expander("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã®æ ¹æ‹ ã¨ãªã£ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè©³ç´°"):
                    st.text_area("å‚ç…§ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ", value=st.session_state.contexts_for_citation, height=300, label_visibility="collapsed")

        # --- å¾“æ¥ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ï¼ˆæ¤œç´¢çµæœæ¦‚è¦ç”¨ï¼‰ ---
        elif st.session_state.is_streaming:
            # ç”Ÿæˆä¸­æ–­ãƒœã‚¿ãƒ³ï¼ˆè«–ç‚¹æŠ½å‡ºç”¨ï¼‰
            if st.button("â¹ï¸ ç”Ÿæˆã‚’ã‚¹ãƒˆãƒƒãƒ—", key="stop_extraction_btn", type="primary"):
                st.session_state.is_streaming = False
                st.rerun()
            
            with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­..."):
                # stream_llm_responseã¯å»ƒæ­¢ã•ã‚ŒãŸãŸã‚ã€Ollamaã‚’ç›´æ¥å‘¼ã³å‡ºã™
                # ã“ã®æ©Ÿèƒ½ã¯å…¸æ‹ ä¸è¦ã®ãŸã‚ã€stream_clean_answerã¯ä½¿ã‚ãªã„
                import ollama
                stream = ollama.chat(
                    model=st.session_state.engine.ollama_model_name,
                    messages=[
                        {'role': 'system', 'content': st.session_state.system_prompt_for_ollama},
                        {'role': 'user', 'content': st.session_state.user_prompt_for_ollama},
                    ],
                    stream=True,
                    options={'temperature': 0.2}
                )
                response_generator = (chunk['message']['content'] for chunk in stream)
                st.session_state.llm_response = st.write_stream(response_generator)
                st.session_state.is_streaming = False
                st.rerun()

        elif st.session_state.llm_response:
            st.markdown("---")
            st.markdown("##### AIã«ã‚ˆã‚‹ãƒ¬ãƒãƒ¼ãƒˆ:")
            st.markdown(st.session_state.llm_response, unsafe_allow_html=True)

if not st.session_state.initialized:
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹ã€‚")
    st.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ–ä¸­...")

    if st.session_state.engine is None:
        try:
            # configãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã§æŒ‡å®š
            config_path = os.path.join(os.path.dirname(__file__), '..', 'configs', 'config.toml')
            
            # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è§£æ (ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ä¸Šæ›¸ãç”¨)
            parser = argparse.ArgumentParser()
            parser.add_argument('--workspace', type=str, default=None, help='ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹')
            args, _ = parser.parse_known_args()

            st.session_state.engine = ScholarScopeEngine(config_path=config_path, workspace_dir=args.workspace)
            setup_logging(st.session_state.engine)
            logger.info("ScholarScopeEngineã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–æˆåŠŸã€‚")

            # --- ã‚¨ãƒ³ã‚¸ãƒ³ã®è¨­å®šå€¤ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’æ›´æ–° ---
            engine_config = st.session_state.engine.config
            st.session_state.max_context_tokens_for_prompt = engine_config['settings']['default_max_context_tokens']
            st.session_state.last_used_max_context_tokens_for_prompt_in_contexts_string = engine_config['settings']['default_max_context_tokens']

        except Exception as e:
            print(f"CRITICAL: ScholarScopeEngineã®åˆæœŸåŒ–ã«å¤±æ•—: {e}")
            st.error(f"ã‚³ã‚¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.session_state.initialization_status = "error"
            st.stop()

    st.session_state.initialized = True
    logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å®Œäº†ã€‚")


# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡¦ç† (ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—) ---
if not st.session_state.rebuild_decision_made:
    logger.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰åˆ¤æ–­ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–‹å§‹ã€‚")
    action, reason = st.session_state.engine.check_and_decide_build_action()

    if action == "STOP":
        st.error(reason)
        st.stop()

    elif action == "LOAD_EMPTY":
        st.info(reason)
        st.session_state.rebuild_decision_made = True
        st.session_state.user_chose_to_rebuild = False

    elif action == "FORCE_REBUILD":
        st.info(reason)
        st.session_state.rebuild_decision_made = True
        st.session_state.user_chose_to_rebuild = True

    elif action == "LOAD":
        st.info(reason)
        st.session_state.rebuild_decision_made = True
        st.session_state.user_chose_to_rebuild = False

    elif action == "ASK_INCREMENTAL":
        st.warning(reason)
        st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æ›´æ–°æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("å·®åˆ†æ›´æ–°ã‚’å®Ÿè¡Œ", key="incremental_update_button", use_container_width=True, type="primary"):
                st.session_state.user_chose_to_incrementally_update = True
                st.session_state.rebuild_decision_made = True
                st.rerun()
        with col2:
            if st.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å…¨å†æ§‹ç¯‰", key="force_rebuild_button_incremental", use_container_width=True):
                st.session_state.user_chose_to_rebuild = True
                st.session_state.rebuild_decision_made = True
                st.rerun()
        st.stop() # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å¾…ã¤

    elif action == "ASK_REBUILD":
        st.warning(reason)
        st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å†æ§‹ç¯‰ãŒå¿…è¦ã§ã™ã€‚")
        if st.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰", key="force_rebuild_button_rebuild", use_container_width=True, type="primary"):
            st.session_state.user_chose_to_rebuild = True
            st.session_state.rebuild_decision_made = True
            st.rerun()
        st.stop() # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®é¸æŠã‚’å¾…ã¤

if st.session_state.rebuild_decision_made and st.session_state.initialization_status not in ["ready", "error"]:

    action_taken = False
    build_params = {}

    if st.session_state.user_chose_to_incrementally_update:
        st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å·®åˆ†æ›´æ–°ã—ã¾ã™ã€‚")
        build_params = {"incremental_update": True}
        action_taken = True
    elif st.session_state.user_chose_to_rebuild:
        st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰/å†æ§‹ç¯‰ã—ã¾ã™ã€‚")
        build_params = {"force_rebuild": True}
        action_taken = True
    elif st.session_state.user_chose_to_rebuild is False:
        st.info("æ—¢å­˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’åˆ©ç”¨ã—ã¾ã™ã€‚")
        build_params = {}
        action_taken = True

    if action_taken:
        with st.spinner("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æº–å‚™ã—ã¦ã„ã¾ã™..."):
            result = st.session_state.engine.build_index(**build_params)

        if result.get("status") == "success":
            st.success(result.get("message", "å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚"))
        else:
            st.warning(result.get("message", "å‡¦ç†ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"))

        st.session_state.initialization_status = "ready"
        st.rerun()

# --- åˆæœŸåŒ–å¾Œã®ãƒ¡ã‚¤ãƒ³UIæç”» ---
if st.session_state.initialization_status != "ready":
    if st.session_state.initialization_status == "error":
        logger.error("åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¦åœæ­¢ã—ã¾ã™ã€‚")
        st.error("åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã™ã‚‹ã‹ã€ç®¡ç†è€…ã«ã”é€£çµ¡ãã ã•ã„ã€‚è©³ç´°ã¯ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    elif st.session_state.initialization_status in ["user_confirm_rebuild", "user_confirm_incremental"]:
        logger.debug(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèªå¾…æ©Ÿä¸­ ({st.session_state.initialization_status})ã€‚UIæç”»ã‚¹ã‚­ãƒƒãƒ—ã€‚")
        pass
    else:
        logger.info(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æº–å‚™ä¸­ ({st.session_state.initialization_status})ã€‚å¾…æ©Ÿãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤ºã€‚")
        st.info(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®æº–å‚™ãŒå®Œäº†ã™ã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„... (çŠ¶æ…‹: {st.session_state.initialization_status})")
    st.stop()

logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æº–å‚™å®Œäº†ã€‚ãƒ¡ã‚¤ãƒ³UIæç”»é–‹å§‹ã€‚")

st.markdown("""
<style>
    div[data-testid="stHorizontalBlock"] > div[data-testid="column"] {
        height: calc(100vh - 10rem); overflow-y: auto; padding-right: 15px; padding-left: 5px;
    }
    .main .block-container { padding-top: 1rem; padding-bottom: 1rem; padding-left: 1rem; padding-right: 1rem; }
</style>
""", unsafe_allow_html=True)

# --- ãƒ˜ãƒƒãƒ€ãƒ¼ ---
header_cols = st.columns([0.7, 0.3])
st.markdown("<hr style='margin: 0; border-top: 1px solid #E0E0E0;'>", unsafe_allow_html=True)
with header_cols[0]:
    st.header("æ–‡çŒ®æ¢ç´¢æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ ", divider=False)

with header_cols[1]:
    # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«è¡¨ç¤º
    workspace_path = st.session_state.engine.workspace_dir
    st.markdown(f"<div style='font-size: 0.8rem; text-align: right;'><b>Workspace:</b> <code>{workspace_path}</code></div>", unsafe_allow_html=True)

    # ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’Popoverã§è¡¨ç¤º
    loaded_files_info = st.session_state.engine.get_loaded_files_info()
    if loaded_files_info:
        with st.popover(f"ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(loaded_files_info)}ä»¶", use_container_width=True):
            st.markdown("##### ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§")
            for finfo in loaded_files_info:
                st.markdown(f"- {finfo['name']}")
    else:
        documents_folder_name = st.session_state.engine.config['paths']['documents_folder']
        st.info(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚`{documents_folder_name}`ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

if st.session_state.show_ai_question_pane:
    main_cols = st.columns([0.25, 0.45, 0.30])
    left_column, center_column, right_column = main_cols[0], main_cols[1], main_cols[2]
    render_right_column()
else:
    main_cols = st.columns([0.35, 0.65])
    left_column, center_column = main_cols[0], main_cols[1]
    right_column = None

# --- å·¦ãƒšã‚¤ãƒ³ (æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ) ---
with left_column:
    st.subheader("æ¤œç´¢è¨­å®š")
    with st.form(key="search_form_left_pane"):
        full_text_query_input = st.text_input(
            "å…¨æ–‡æ¤œç´¢ï¼ˆçµã‚Šè¾¼ã¿ï¼‰",
            value=st.session_state.last_executed_full_text_query,
            key="input_full_text",
            placeholder=st.session_state.engine.config.get('ui', {}).get('must_keywords_placeholder', "ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§ANDæ¤œç´¢ã€-ã§é™¤å¤–æ¤œç´¢"),
            help="ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§ANDæ¤œç´¢ã€‚å˜èªã®å‰ã« `-` ã‚’ä»˜ã‘ã‚‹ã¨é™¤å¤–æ¤œç´¢ã«ãªã‚Šã¾ã™ã€‚"
        )
        with st.expander("çµã‚Šè¾¼ã¿ã‚’è¿½åŠ "):
            doc_name_filter_input = st.text_input(
                "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå",
                value=st.session_state.last_executed_doc_name_filter,
                key="input_doc_name_filter",
                placeholder=st.session_state.engine.config.get('ui', {}).get('must_keywords_placeholder', "ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§ANDæ¤œç´¢ã€-ã§é™¤å¤–æ¤œç´¢"),
                help="ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåã§çµã‚Šè¾¼ã¿ã¾ã™ã€‚ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§ANDæ¤œç´¢ã€-ã§é™¤å¤–æ¤œç´¢ãŒã§ãã¾ã™ã€‚"
            )
        with st.expander("æ„å‘³ãƒ»æ–‡è„ˆã§æ¤œç´¢ï¼ˆAIåˆ©ç”¨ï¼‰"):

            semantic_query_input = st.text_area(
                "è³ªå•ãƒ»é–¢å¿ƒäº‹",
                value=st.session_state.last_executed_semantic_query,
                key="input_semantic_query",
                height=150,
                placeholder=st.session_state.engine.config.get('ui', {}).get('semantic_query_placeholder', "ä¾‹: æ˜æ²»20å¹´é ƒã®æ¡ç´„æ”¹æ­£ã®å‹•ãã«ã¤ã„ã¦çŸ¥ã‚ŠãŸã„"),
                help="è³ªå•ãƒ»é–¢å¿ƒäº‹ã‚’è‡ªç„¶ãªæ–‡ç« ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n\nğŸ’¡ **ä¾¿åˆ©ãªæ©Ÿèƒ½**\n- **å’Œæš¦/è¥¿æš¦ã®è‡ªå‹•è£œå®Œ**: ã€Œæ˜æ²»20å¹´ã€ã¨å…¥åŠ›ã™ã‚‹ã¨ã€å†…éƒ¨ã§ã€Œæ˜æ²»20å¹´ï¼ˆ1887å¹´ï¼‰ã€ã®ã‚ˆã†ã«å¤‰æ›ã•ã‚Œã€ã©ã¡ã‚‰ã®è¡¨è¨˜ã§ã‚‚ãƒ’ãƒƒãƒˆã™ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚"
            )
            use_ai_optimization = st.toggle(
                "æ¤œç´¢ã‚¯ã‚¨ãƒªã®æœ€é©åŒ–",
                value=True,
                help="ã€ONã€‘AIãŒè³ªå•ã®æ„å›³ã‚’è§£é‡ˆã—ã€å„æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ»ãƒ™ã‚¯ãƒˆãƒ«ãƒ»ãƒªãƒ©ãƒ³ã‚¯ï¼‰ã«åˆã‚ã›ã¦æœ€é©ãªå½¢ã«æ›¸ãæ›ãˆã¾ã™ã€‚æ›–æ˜§ãªè³ªå•ã§ã‚‚ãƒ’ãƒƒãƒˆã—ã‚„ã™ããªã‚Šã¾ã™ã€‚\n\nã€OFFã€‘å…¥åŠ›æ–‡ã‚’ãã®ã¾ã¾ä½¿ç”¨ã—ã¾ã™ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ã®å½¢æ…‹ç´ è§£æã¯è¡Œã‚ã‚Œã¾ã™ï¼‰ã€‚\nå°‚é–€ç”¨èªã‚’å³å¯†ã«æ¤œç´¢ã—ãŸã„å ´åˆã‚„ã€AIã«ã‚ˆã‚‹æ„è¨³ãƒ»è¦ç´„ã§é‡è¦ãªå˜èªãŒçœç•¥ã•ã‚Œã¦ã—ã¾ã†ã®ã‚’é˜²ããŸã„å ´åˆã¯ã€OFFã®æ–¹ãŒè‰¯ã„çµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚"
            )
            
            # è¨­å®šå€¤ã‚’å–å¾—ï¼ˆè¡¨ç¤ºç”¨ï¼‰
            std_count = st.session_state.engine.reranker_input_count
            deep_count = st.session_state.engine.reranker_input_count_deep

            # UIç°¡ç•¥åŒ–: ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ON/OFFã®ã¿ã«ã™ã‚‹ (GPUæœ‰åŠ¹åŒ–ã«ä¼´ã„Deepã§ã‚‚é«˜é€ŸãªãŸã‚)
            is_rerank_active = st.toggle(
                "é–¢é€£åº¦é †ã‚½ãƒ¼ãƒˆï¼ˆAIåˆ©ç”¨ï¼‰",
                value=not st.session_state.skip_rerank,
                help=f"ã€ONã€‘æ¤œç´¢å€™è£œã®ä¸Šä½ï¼ˆæœ€å¤§{deep_count*2}ä»¶ï¼‰ã«ã¤ã„ã¦ã€AIãŒæœ¬æ–‡ã‚’èª­ã¿è¾¼ã‚“ã§è³ªå•ã¨ã®é–¢é€£æ€§ã‚’åˆ¤å®šãƒ»ä¸¦ã¹æ›¿ãˆã‚’è¡Œã„ã¾ã™ã€‚ã‚ˆã‚Šçš„ç¢ºãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚\n\nã€OFFã€‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å‡ºç¾é »åº¦ã‚„å˜ç´”ãªé¡ä¼¼åº¦é †ã«è¡¨ç¤ºã—ã¾ã™ã€‚é«˜é€Ÿã§ã™ãŒã€AIã«ã‚ˆã‚‹è©³ç´°ãªç²¾æŸ»ã¯è¡Œã‚ã‚Œã¾ã›ã‚“ã€‚"
            )

        search_submit_button = st.form_submit_button("æ¤œç´¢å®Ÿè¡Œ", type="primary", disabled=st.session_state.is_searching)

    if search_submit_button:
        full_text_query = full_text_query_input.strip()
        doc_name_filter = doc_name_filter_input.strip()
        semantic_query = semantic_query_input.strip()

        # å…¨æ–‡æ¤œç´¢ã‹ã‚‰å¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹
        all_keywords = full_text_query.split()
        must_keywords_list = [kw for kw in all_keywords if not kw.startswith('-')]
        exclude_keywords_list = [kw[1:] for kw in all_keywords if kw.startswith('-') and len(kw) > 1]
        must_keywords = " ".join(must_keywords_list)

        if not must_keywords and not semantic_query:
            st.warning("ã€Œå¿…é ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã¾ãŸã¯ã€Œè³ªå•ãƒ»é–¢å¿ƒäº‹ã€ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            # ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®é¸æŠå€¤ã‹ã‚‰ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
            skip_rerank_req = False
            # ãƒˆã‚°ãƒ«ãŒOFFãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ã€ONãªã‚‰Deepãƒ¢ãƒ¼ãƒ‰(æœ€å¤§ä»¶æ•°)ã§å®Ÿè¡Œ
            if not is_rerank_active:
                skip_rerank_req = True
            # Deepãƒ¢ãƒ¼ãƒ‰ã‚’å¸¸ã«æœ‰åŠ¹ã«ã™ã‚‹ï¼ˆä»¶æ•°ã¯configã§åˆ¶å¾¡ï¼‰
            deep_search_req = True

            # æ¤œç´¢å®Ÿè¡Œæ™‚ã«çµæœã‚’ã‚¯ãƒªã‚¢ã—ã€å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
            st.session_state.and_search_results = []
            st.session_state.keyword_search_results = []
            st.session_state.vector_search_results = []
            st.session_state.reranked_search_results = []
            st.session_state.search_result_meta = {}
            st.session_state.llm_response = ""
            st.session_state.clean_answer = ""
            st.session_state.final_answer = ""
            st.session_state.search_was_cancelled = False # æ–°è¦æ¤œç´¢æ™‚ã¯ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ä¸‹ã’ã‚‹

            # å„æ¤œç´¢çµæœã®å±•é–‹çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            if 'reranked_results_expanded_state' in st.session_state: st.session_state.reranked_results_expanded_state = None
            if 'and_results_expanded_state' in st.session_state: st.session_state.and_results_expanded_state = None
            if 'bm25_results_expanded_state' in st.session_state: st.session_state.bm25_results_expanded_state = None
            if 'vector_results_expanded_state' in st.session_state: st.session_state.vector_results_expanded_state = None
            if 'and_results_expanded_state_skip' in st.session_state: st.session_state.and_results_expanded_state_skip = None

            # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
            st.session_state.search_request = {
                "must_keywords": must_keywords,
                "exclude_keywords": exclude_keywords_list,
                "doc_name_filter": doc_name_filter,
                "semantic_query": semantic_query,
                "skip_rerank": skip_rerank_req,
                "full_text_query": full_text_query, # UIè¡¨ç¤ºç”¨ã«ä¿å­˜
                "use_ai_optimization": use_ai_optimization,
                "deep_search": deep_search_req
            }
            st.session_state.is_searching = True # å‡¦ç†é–‹å§‹ãƒ•ãƒ©ã‚°
            logger.info("æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä»˜ã€‚å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
            st.rerun() # UIã‚’å³æ™‚æ›´æ–°ã—ã¦çµæœã‚’ã‚¯ãƒªã‚¢ã—ã€ãƒœã‚¿ãƒ³ã‚’ç„¡åŠ¹åŒ–

    # --- æ¡ä»¶ã‚¯ãƒªã‚¢ / æ¤œç´¢ä¸­æ­¢ ãƒœã‚¿ãƒ³ (ãƒ•ã‚©ãƒ¼ãƒ å¤–) ---
    if not st.session_state.is_searching:
        # on_clickã‚’ä½¿ã†ã“ã¨ã§ã€æ¬¡ã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆæç”»å‰ã«å€¤ã‚’ãƒªã‚»ãƒƒãƒˆã§ãã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
        st.button("ğŸ—‘ï¸ æ¡ä»¶ãƒ»æ¤œç´¢çµæœã‚’ã‚¯ãƒªã‚¢", use_container_width=True, on_click=reset_application_state)

    # --- æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å‡¦ç† ---
    if st.session_state.is_searching and st.session_state.search_request:
        req = st.session_state.search_request
        must_keywords = req["must_keywords"]
        exclude_keywords = req["exclude_keywords"]
        doc_name_filter = req["doc_name_filter"]
        semantic_query = req["semantic_query"]
        skip_rerank_val = req["skip_rerank"]
        full_text_query = req["full_text_query"]
        use_ai_optimization_val = req.get("use_ai_optimization", False)
        deep_search_val = req.get("deep_search", False)

        st.session_state.skip_rerank = skip_rerank_val
        st.session_state.is_deep_search_mode = deep_search_val
        logger.info(f"æ¤œç´¢å®Ÿè¡Œã€‚å¿…é ˆ: '{must_keywords}', è³ªå•: '{semantic_query}', Deep: {deep_search_val}, ã‚¹ã‚­ãƒƒãƒ—: {skip_rerank_val}")
        st.session_state.last_executed_must_keywords = must_keywords
        st.session_state.last_executed_full_text_query = full_text_query
        st.session_state.last_executed_doc_name_filter = doc_name_filter
        st.session_state.last_executed_semantic_query = semantic_query
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆç”¨ã®è³ªå•æ–‡ã«ã‚‚æ—¥ä»˜æ­£è¦åŒ–ã‚’é©ç”¨ã—ã¦ã‚»ãƒƒãƒˆã™ã‚‹
        raw_question_text = semantic_query or must_keywords
        if raw_question_text:
            st.session_state.current_ai_question_text = st.session_state.engine.date_standardizer.process_text(raw_question_text)
        else:
            st.session_state.current_ai_question_text = ""
            
        st.session_state.executed_and_query_for_highlight = must_keywords
        st.session_state.executed_bm25_query_for_highlight = semantic_query
        st.session_state.executed_semantic_query_for_highlight = semantic_query
        st.session_state.executed_optimized_bm25_query = None # ãƒªã‚»ãƒƒãƒˆ
        st.session_state.executed_rerank_query = None # ãƒªã‚»ãƒƒãƒˆ

        # --- é€²æ—è¡¨ç¤ºç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®šç¾© ---
        with center_column:
            st.subheader("æ¤œç´¢çµæœ")
            search_status_container = st.status("æ¤œç´¢ãƒ—ãƒ­ã‚»ã‚¹å®Ÿè¡Œä¸­...", expanded=True)
            status_placeholder = search_status_container.empty()
            progress_bar_placeholder = search_status_container.empty()

            if st.button("â›” æ¤œç´¢ã‚’ä¸­æ­¢", key="stop_search_center", type="primary", use_container_width=True):
                st.session_state.is_searching = False
                st.session_state.search_request = None
                st.session_state.search_was_cancelled = True # ä¸­æ–­ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                logger.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚Šæ¤œç´¢ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
                st.rerun()

        # çŠ¶æ…‹ç®¡ç†ç”¨è¾æ›¸
        prog_state = {
            "steps": [
                {"key": "query_opt", "label": "ğŸ¤” è³ªå•ãƒ»é–¢å¿ƒäº‹ã®åˆ†æ", "status": "pending", "detail": ""},
                {"key": "retrieval", "label": "ğŸ“š å€™è£œã‚’åºƒãåé›†", "status": "pending", "detail": ""},
                {"key": "filter", "label": "ğŸ§¹ å€™è£œã®æ•´ç†ãƒ»çµ±åˆ", "status": "pending", "detail": ""},
                {"key": "rerank", "label": "ğŸ‘€ å†…å®¹ã®ç²¾æŸ»", "status": "pending", "detail": "", "progress": 0, "total": 0}
            ]
        }

        def render_progress():
            md_lines = []
            for step in prog_state["steps"]:
                icon = "â¬œ"
                if step["status"] == "running": icon = "ğŸ”„"
                elif step["status"] == "done": icon = "âœ…"
                elif step["status"] == "skipped": icon = "â­ï¸"
                
                # detailãŒç©ºãªã‚‰çŠ¶æ…‹ã«å¿œã˜ãŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ–‡ã‚’è¡¨ç¤º
                msg = step["detail"]
                if not msg:
                    if step["status"] == "pending": msg = "å¾…æ©Ÿä¸­..."
                    elif step["status"] == "running": msg = "å®Ÿè¡Œä¸­..."
                
                md_lines.append(f"{icon} **{step['label']}**: {msg}")
            
            status_placeholder.markdown("\n\n".join(md_lines))
            
            # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã®ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼åˆ¶å¾¡
            rerank_step = prog_state["steps"][3]
            if rerank_step["status"] == "running" and rerank_step["total"] > 0:
                pct = min(rerank_step["progress"] / rerank_step["total"], 1.0)
                progress_bar_placeholder.progress(pct)
            else:
                progress_bar_placeholder.empty()

        def update_step_status(key, status, detail=None):
            for step in prog_state["steps"]:
                if step["key"] == key:
                    step["status"] = status
                    if detail is not None: step["detail"] = detail
            render_progress()

        def search_progress_callback(phase, status=None, detail=None, current=None, total=None):
            """
            phase: 'start', 'query_opt', 'retrieval', 'filter', 'rerank', 'done'
            status: 'running', 'done', 'skipped', 'failed' (phase='start'/'done'ã®å ´åˆã¯çœç•¥å¯)
            detail: è¡¨ç¤ºã™ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ–‡å­—åˆ—
            """
            if phase == 'start':
                render_progress()
            
            elif phase == 'query_opt':
                if status == 'running':
                    # ã‚¨ãƒ³ã‚¸ãƒ³ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šæ›¸ãã—ã¦ã€ã‚ˆã‚Šè¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã«
                    update_step_status("query_opt", "running", "AIãŒæ¤œç´¢ã®æ„å›³ã‚’è§£é‡ˆã—ã¦ã„ã¾ã™...")
                elif status == 'skipped':
                    update_step_status("query_opt", "skipped", "ã‚¹ã‚­ãƒƒãƒ— (å…ƒã®å…¥åŠ›ã‚’ãã®ã¾ã¾ä½¿ç”¨)")
                elif status == 'done':
                    update_step_status("query_opt", "done", detail)

            elif phase == 'retrieval':
                if status == 'running':
                    update_step_status("retrieval", "running", "é–¢é€£ã—ãã†ãªç®‡æ‰€ã‚’é›†ã‚ã¦ã„ã¾ã™...")
                elif status == 'done':
                    update_step_status("retrieval", "done", detail)

            elif phase == 'filter':
                if status == 'running':
                    update_step_status("filter", "running", "é‡è¤‡ã‚„æ¡ä»¶å¤–ã®ã‚‚ã®ã‚’é™¤å¤–ã—ã¦ã„ã¾ã™...")
                elif status == 'done':
                    update_step_status("filter", "done", detail)

            elif phase == 'rerank':
                step = prog_state["steps"][3]
                if current is not None and total is not None:
                    step["status"] = "running"
                    step["progress"] = current
                    step["total"] = total
                    # é€²æ—è¡¨ç¤ºã‚’ã‚ˆã‚Šåˆ†ã‹ã‚Šã‚„ã™ã
                    step["detail"] = f"AIãŒæœ¬æ–‡ã‚’è§£æã—ã€é–¢é€£åº¦é †ã«ä¸¦ã¹ã¦ã„ã¾ã™ ({current} / {total} ä»¶)"
                    render_progress()
                elif status == 'running':
                    update_step_status("rerank", "running", "AIãŒæœ¬æ–‡ã‚’è§£æã—ã€é–¢é€£åº¦é †ã«ä¸¦ã¹ã¦ã„ã¾ã™...")
                elif status == 'done':
                    update_step_status("rerank", "done", "å®Œäº† (é–¢é€£åº¦é †ã«ä¸¦ã¹æ›¿ãˆ)")
                elif status == 'skipped':
                    update_step_status("rerank", "skipped", "ã‚¹ã‚­ãƒƒãƒ— (é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰)")

            elif phase == 'done':
                # å…¨å·¥ç¨‹ãŒå®Œäº†ã—ãŸã‚‰ã‚³ãƒ³ãƒ†ãƒŠã‚’ç•³ã‚€
                search_status_container.update(label="æ¤œç´¢å‡¦ç†å®Œäº†", state="complete", expanded=False)

        search_start_time = time.time()

        try:
            optimized_queries = None
            if use_ai_optimization_val and semantic_query:
                search_progress_callback('start')
                search_progress_callback('query_opt', 'running', "åˆ†æä¸­...")
                optimized_queries = st.session_state.engine.optimize_search_queries(semantic_query)
                
                if optimized_queries:
                    # ã‚·ãƒ³ãƒ—ãƒ«ãªè¡¨ç¤ºã«ã™ã‚‹
                    q_summary = f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {optimized_queries['bm25_query'][:15]}..., ãƒ™ã‚¯ãƒˆãƒ«: {optimized_queries['vector_query'][:15]}..."
                    search_progress_callback('query_opt', 'done', q_summary)
                    
                    # ãƒã‚¤ãƒ©ã‚¤ãƒˆç”¨å¤‰æ•°ã®æ›´æ–°
                    st.session_state.executed_bm25_query_for_highlight = optimized_queries['bm25_query']
                    st.session_state.executed_semantic_query_for_highlight = optimized_queries['vector_query']
                    st.session_state.executed_optimized_bm25_query = optimized_queries['bm25_query']
                    st.session_state.executed_rerank_query = optimized_queries.get('rerank_query')
                else:
                    search_progress_callback('query_opt', 'skipped') # å¤±æ•—æ™‚ã¯ã‚¹ã‚­ãƒƒãƒ—æ‰±ã„
            else:
                 # æœ€é©åŒ–OFFã®å ´åˆ
                 search_progress_callback('start')
                 search_progress_callback('query_opt', 'skipped')

            search_results_dict = st.session_state.engine.search(
                must_keywords=must_keywords,
                semantic_query=semantic_query,
                doc_name_filter=doc_name_filter,
                exclude_keywords=exclude_keywords,
                skip_rerank=st.session_state.skip_rerank,
                optimized_queries=optimized_queries,
                deep_search=deep_search_val,
                callback=search_progress_callback
            )
            search_progress_callback('done')
        
        except Exception as e:
            search_status_container.update(label="æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", state="error")
            logger.error(f"æ¤œç´¢å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            st.stop()
            
        st.session_state.last_search_duration = time.time() - search_start_time

        # æ¤œç´¢çµæœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«æ ¼ç´
        st.session_state.and_search_results = search_results_dict.get("and", [])
        st.session_state.keyword_search_results = search_results_dict.get("bm25", [])
        st.session_state.vector_search_results = search_results_dict.get("vector", [])
        st.session_state.reranked_search_results = search_results_dict.get("reranked", [])
        st.session_state.search_result_meta = search_results_dict.get("meta", {})

        try:
            search_hits_info = {
                "and": len(st.session_state.and_search_results),
                "bm25": len(st.session_state.keyword_search_results),
                "vector": len(st.session_state.vector_search_results),
                "reranked": len(st.session_state.reranked_search_results)
            }
            unique_hit_sources_for_history = set()
            all_docs_for_history = st.session_state.and_search_results + \
                                   [doc for doc, score in st.session_state.keyword_search_results] + \
                                   [doc for doc, score in st.session_state.vector_search_results]
            for doc in all_docs_for_history:
                if doc.metadata.get("source"):
                    unique_hit_sources_for_history.add(doc.metadata["source"])

            history_entry_to_save = {
                "timestamp": datetime.datetime.now().isoformat(),
                "must_keywords": must_keywords,
                "semantic_query": semantic_query,
                "hits_per_method": search_hits_info,
                "unique_source_documents_hit": len(unique_hit_sources_for_history)
            }
            save_search_history(history_entry_to_save)
        except Exception as e_hist:
            logger.error(f"æ¤œç´¢å±¥æ­´ã®ä½œæˆã¾ãŸã¯ä¿å­˜å‘¼ã³å‡ºã—ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e_hist}", exc_info=True)

        logger.info("æ¤œç´¢å‡¦ç†å®Œäº†ã€‚UIã‚’å†æç”»ã—ã¾ã™ã€‚")
        st.session_state.is_searching = False # å‡¦ç†å®Œäº†
        st.session_state.search_request = None # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
        st.rerun()

    # --- æœ€é©åŒ–çµæœã®äº‹å¾Œè¡¨ç¤º ---
    if st.session_state.executed_optimized_bm25_query and st.session_state.search_request is None:
         with st.expander("ğŸ’¡ AIã«ã‚ˆã‚‹ã‚¯ã‚¨ãƒªæœ€é©åŒ–çµæœ", expanded=False):
            st.markdown(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨:** `{st.session_state.executed_bm25_query_for_highlight}`")
            st.markdown(f"**ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨:** `{st.session_state.executed_semantic_query_for_highlight}`")
            if not st.session_state.skip_rerank and st.session_state.get('executed_rerank_query'):
                st.markdown(f"**ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ç”¨:** `{st.session_state.executed_rerank_query}`")

    st.divider()
    st.subheader("è¡¨ç¤ºè¨­å®š")
    show_pane_checkbox_val_left = st.checkbox(
        "AIåˆ†æãƒ‘ãƒãƒ«ã‚’è¡¨ç¤º", value=st.session_state.show_ai_question_pane,
        key="cb_show_ai_pane_left_key", help="å³å´ã«æ¤œç´¢çµæœã‚’ä½¿ã£ãŸAIåˆ†æãƒ‘ãƒãƒ«ã‚’è¡¨ç¤º/éè¡¨ç¤ºã—ã¾ã™ã€‚"
    )
    if show_pane_checkbox_val_left != st.session_state.show_ai_question_pane:
        st.session_state.show_ai_question_pane = show_pane_checkbox_val_left
        logger.debug(f"AIæ¦‚è¦ãƒ‘ãƒãƒ«è¡¨ç¤ºçŠ¶æ…‹å¤‰æ›´: {st.session_state.show_ai_question_pane}")
        st.rerun()

# --- ä¸­å¤®ãƒšã‚¤ãƒ³ (æ¤œç´¢çµæœè¡¨ç¤º) ---
with center_column:
    st.subheader("æ¤œç´¢çµæœ")
    show_individual_results = False # ã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚äº‹å‰ã«åˆæœŸåŒ–
    any_query_executed = st.session_state.last_executed_must_keywords or st.session_state.last_executed_semantic_query
    if any_query_executed:
        all_hit_docs_for_stats = []
        if st.session_state.reranked_search_results: all_hit_docs_for_stats.extend([doc for doc, score in st.session_state.reranked_search_results])
        if st.session_state.and_search_results: all_hit_docs_for_stats.extend(st.session_state.and_search_results)
        if st.session_state.keyword_search_results: all_hit_docs_for_stats.extend([doc for doc, score in st.session_state.keyword_search_results])
        if st.session_state.vector_search_results: all_hit_docs_for_stats.extend([doc for doc, score in st.session_state.vector_search_results])

        unique_hit_source_names = set()
        if all_hit_docs_for_stats:
            for doc_for_stats in all_hit_docs_for_stats:
                source_name_for_stats = doc_for_stats.metadata.get("source")
                if source_name_for_stats:
                    unique_hit_source_names.add(Path(source_name_for_stats).name)

        loaded_files_info = st.session_state.engine.get_loaded_files_info()
        total_uploaded_docs = len(loaded_files_info)

        if total_uploaded_docs > 0:
            duration_html = f" <span style='color:gray; font-size:0.8rem; margin-left:10px;'>({st.session_state.last_search_duration:.2f}ç§’)</span>" if st.session_state.last_search_duration > 0 else ""
            st.markdown(f"**ãƒ’ãƒƒãƒˆæ–‡æ›¸:** {len(unique_hit_source_names)} / {total_uploaded_docs} ä»¶{duration_html}", unsafe_allow_html=True)
            if unique_hit_source_names:
                with st.expander("ãƒ’ãƒƒãƒˆã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ (ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)"):
                    for name in sorted(list(unique_hit_source_names)): st.markdown(f"- {name}")
            st.markdown("---")

    active_search_results_exist = False

    # 1. ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°çµæœ (æœ€å„ªå…ˆã§è¡¨ç¤º)
    if st.session_state.reranked_search_results:
        active_search_results_exist = True

        # è¡¨ç¤ºã™ã‚‹ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‹•çš„ã«å¤‰æ›´
        num_reranked = len(st.session_state.reranked_search_results)

        header_cols_reranked = st.columns([0.8, 0.2])
        with header_cols_reranked[0]:
            if st.session_state.last_executed_must_keywords:
                st.markdown(f"#### AIã«ã‚ˆã‚‹å†è©•ä¾¡ï¼šé–¢é€£åº¦ã®é«˜ã„é † {num_reranked}ä»¶ï¼ˆçµè¾¼ã‚ã‚Šï¼‰", unsafe_allow_html=True)
            else:
                st.markdown(f"#### AIã«ã‚ˆã‚‹å†è©•ä¾¡ï¼šé–¢é€£åº¦ã®é«˜ã„é † {num_reranked}ä»¶", unsafe_allow_html=True)
        with header_cols_reranked[1]:
            if 'reranked_results_expanded_state' not in st.session_state:
                st.session_state.reranked_results_expanded_state = None # None: åˆæœŸ, True: å…¨å±•é–‹, False: å…¨é–‰ã˜ã‚‹
            button_label_reranked = "ã™ã¹ã¦å±•é–‹" if st.session_state.reranked_results_expanded_state in [None, False] else "ã™ã¹ã¦é–‰ã˜ã‚‹"
            if st.button(button_label_reranked, key="toggle_reranked", use_container_width=True):
                st.session_state.reranked_results_expanded_state = not st.session_state.reranked_results_expanded_state in [True]
                st.rerun()

        # ãƒã‚¤ãƒ©ã‚¤ãƒˆç”¨ã®ã‚¯ã‚¨ãƒªã‚’æ±ºå®š
        if st.session_state.executed_optimized_bm25_query:
            query_for_highlight = st.session_state.executed_optimized_bm25_query
        else:
            query_for_highlight = st.session_state.last_executed_semantic_query or st.session_state.last_executed_must_keywords

        query_terms_for_highlight = highlight.get_query_terms_for_highlight(
            query_for_highlight,
            search_type="bm25", # æ„å‘³æ¤œç´¢ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã¯BM25æ–¹å¼ãŒé©ã—ã¦ã„ã‚‹
            tokenizer_instance=st.session_state.engine.tokenizer
        )

        num_to_expand = st.session_state.engine.initially_expanded_results_count

        for i, (chunk_doc, score) in enumerate(st.session_state.reranked_search_results): # reranker_input_count * 2 ä»¶ãŒæœ€å¤§
            source_full_path = chunk_doc.metadata.get("source", "N/A")
            source_filename = Path(source_full_path).name
            page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
            page_num_info = f", Page: {page_num_str}" if page_num_str.isdigit() else ""

            # ã‚ªãƒ¬ãƒ³ã‚¸ -> è–„ã„ã‚ªãƒ¬ãƒ³ã‚¸ã«å¤‰æ›´
            highlighted_content = highlight.highlight_text(chunk_doc.page_content, query_terms_for_highlight, default_color="#FFE0B2", search_type="bm25")

            # --- expandedãƒ­ã‚¸ãƒƒã‚¯ ---
            is_expanded = False
            if st.session_state.reranked_results_expanded_state is True:
                is_expanded = True
            elif st.session_state.reranked_results_expanded_state is False:
                is_expanded = False
            else: # åˆæœŸçŠ¶æ…‹
                is_expanded = (i < num_to_expand)
            # --- ã“ã“ã¾ã§ ---

            with st.expander(f"**{i+1}.** {source_filename}{page_num_info} (é–¢é€£åº¦ã‚¹ã‚³ã‚¢: **{score:.4f}**)", expanded=is_expanded):
                st.markdown(highlighted_content, unsafe_allow_html=True)

        # --- ã€Œãã®ä»–ã®å€™è£œã€ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ ---
        # ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã«ä½¿ã‚ã‚Œãªã‹ã£ãŸæ®‹ã‚Šã®å€™è£œã‚’è¡¨ç¤º
        other_bm25_results = st.session_state.keyword_search_results[st.session_state.engine.reranker_input_count:]
        other_vector_results = st.session_state.vector_search_results[st.session_state.engine.reranker_input_count:]

        if other_bm25_results or other_vector_results:
            st.markdown("---")
            header_cols_other = st.columns([0.8, 0.2])
            with header_cols_other[0]:
                st.markdown("#### ãã®ä»–ã®å€™è£œ")
            with header_cols_other[1]:
                if 'other_results_expanded_state' not in st.session_state:
                    st.session_state.other_results_expanded_state = None
                button_label_other = "ã™ã¹ã¦å±•é–‹" if st.session_state.other_results_expanded_state in [None, False] else "ã™ã¹ã¦é–‰ã˜ã‚‹"
                if st.button(button_label_other, key="toggle_other", use_container_width=True):
                    st.session_state.other_results_expanded_state = not st.session_state.other_results_expanded_state in [True]
                    st.rerun()

            is_expanded_other = st.session_state.other_results_expanded_state is True

            if other_bm25_results:
                # é»’æ–‡å­— + æ°´è‰²èƒŒæ™¯ãƒãƒƒã‚¸é¢¨
                st.markdown(f"##### <span style='background-color:#B2EBF2; color:black; padding:2px 6px; border-radius:4px;'>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢é †</span>ï¼ˆä¸Šä½{len(other_bm25_results)}ä»¶ï¼‰", unsafe_allow_html=True)
                query_tokens_for_kw_highlight = highlight.get_query_terms_for_highlight(
                    st.session_state.executed_bm25_query_for_highlight, search_type="bm25",
                    tokenizer_instance=st.session_state.engine.tokenizer
                )
                for i, (chunk_doc, score) in enumerate(other_bm25_results):
                    source_full_path = chunk_doc.metadata.get("source", "N/A")
                    source_filename = Path(source_full_path).name
                    page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
                    page_num_info = f", Page: {page_num_str}" if page_num_str != "N/A" and page_num_str.isdigit() else ""
                    highlighted_content_kw = highlight.highlight_text(chunk_doc.page_content, query_tokens_for_kw_highlight, search_type="bm25")
                    with st.expander(f"BM25-{i+st.session_state.engine.reranker_input_count+1}. {source_filename}{page_num_info} (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢: {score:.4f})", expanded=is_expanded_other):
                        st.markdown(highlighted_content_kw, unsafe_allow_html=True)
                st.markdown("<br>", unsafe_allow_html=True)

            if other_vector_results:
                # é»’æ–‡å­— + è–„ç´«èƒŒæ™¯ãƒãƒƒã‚¸é¢¨
                st.markdown(f"##### <span style='background-color:#E1BEE7; color:black; padding:2px 6px; border-radius:4px;'>æ„å‘³ãŒè¿‘ã„é †</span>ï¼ˆä¸Šä½{len(other_vector_results)}ä»¶ï¼‰", unsafe_allow_html=True)
                query_terms_for_vec_highlight = highlight.get_query_terms_for_highlight(st.session_state.executed_semantic_query_for_highlight, search_type="vector")
                for i, (chunk_doc, score) in enumerate(other_vector_results):
                    source_full_path = chunk_doc.metadata.get("source", "N/A")
                    source_filename = Path(source_full_path).name
                    page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
                    page_num_info = f", Page: {page_num_str}" if page_num_str != "N/A" and page_num_str.isdigit() else ""
                    highlighted_content_vec = highlight.highlight_text(chunk_doc.page_content, query_terms_for_vec_highlight, default_color="#E1BEE7", search_type="vector")
                    with st.expander(f"Vector-{i+st.session_state.engine.reranker_input_count+1}. {source_filename}{page_num_info} (AIé¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.4f})", expanded=is_expanded_other):
                        st.markdown(highlighted_content_vec, unsafe_allow_html=True)

        st.markdown("---")

    # 2. ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸå ´åˆã®çµ±åˆè¡¨ç¤º
    elif st.session_state.last_executed_semantic_query and st.session_state.skip_rerank:
        st.markdown("#### æ¤œç´¢çµæœï¼ˆAIã«ã‚ˆã‚‹é–¢é€£åº¦é †ä½ä»˜ã‘ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¦ã„ã¾ã™ï¼‰", unsafe_allow_html=True)

        # BM25ã®çµæœ
        if st.session_state.keyword_search_results:
            header_cols_bm25 = st.columns([0.8, 0.2])
            with header_cols_bm25[0]:
                # é»’æ–‡å­— + æ°´è‰²èƒŒæ™¯ãƒãƒƒã‚¸é¢¨
                st.markdown(f"##### <span style='background-color:#B2EBF2; color:black; padding:2px 6px; border-radius:4px;'>ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢é †</span>ï¼ˆä¸Šä½{len(st.session_state.keyword_search_results)}ä»¶ï¼‰", unsafe_allow_html=True)
            with header_cols_bm25[1]:
                if 'bm25_results_expanded_state' not in st.session_state:
                    st.session_state.bm25_results_expanded_state = None
                button_label_bm25 = "ã™ã¹ã¦å±•é–‹" if st.session_state.bm25_results_expanded_state in [None, False] else "ã™ã¹ã¦é–‰ã˜ã‚‹"
                if st.button(button_label_bm25, key="toggle_bm25_skip", use_container_width=True):
                    st.session_state.bm25_results_expanded_state = not st.session_state.bm25_results_expanded_state in [True]
                    st.rerun()
            query_tokens_for_kw_highlight = highlight.get_query_terms_for_highlight(
                st.session_state.executed_bm25_query_for_highlight,
                search_type="bm25",
                tokenizer_instance=st.session_state.engine.tokenizer
            )
            num_to_expand = st.session_state.engine.initially_expanded_results_count
            for i, (chunk_doc, score) in enumerate(st.session_state.keyword_search_results): # ã‚¹ãƒ©ã‚¤ã‚¹ã‚’å‰Šé™¤ã—å…¨ä»¶è¡¨ç¤º
                source_full_path = chunk_doc.metadata.get("source", "N/A")
                source_filename = Path(source_full_path).name
                page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
                page_num_info = f", Page: {page_num_str}" if page_num_str != "N/A" and page_num_str.isdigit() else ""
                highlighted_content_kw = highlight.highlight_text(chunk_doc.page_content, query_tokens_for_kw_highlight, search_type="bm25")

                # --- expandedãƒ­ã‚¸ãƒƒã‚¯ ---
                is_expanded = False
                if st.session_state.bm25_results_expanded_state is True: is_expanded = True
                elif st.session_state.bm25_results_expanded_state is False: is_expanded = False
                else: is_expanded = (i < num_to_expand)

                with st.expander(f"{i+1}. {source_filename}{page_num_info} (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚¹ã‚³ã‚¢: {score:.4f})", expanded=is_expanded):
                    st.markdown(highlighted_content_kw, unsafe_allow_html=True)
            active_search_results_exist = True
            st.markdown("<br>", unsafe_allow_html=True)

        # Vectorã®çµæœ
        if st.session_state.vector_search_results:
            header_cols_vector = st.columns([0.8, 0.2])
            with header_cols_vector[0]:
                st.markdown(f"##### <span style='background-color:#E1BEE7; color:black; padding:2px 6px; border-radius:4px;'>æ„å‘³ãŒè¿‘ã„é †</span>ï¼ˆä¸Šä½{len(st.session_state.vector_search_results)}ä»¶ï¼‰", unsafe_allow_html=True)
            with header_cols_vector[1]:
                if 'vector_results_expanded_state' not in st.session_state:
                    st.session_state.vector_results_expanded_state = None
                button_label_vector = "ã™ã¹ã¦å±•é–‹" if st.session_state.vector_results_expanded_state in [None, False] else "ã™ã¹ã¦é–‰ã˜ã‚‹"
                if st.button(button_label_vector, key="toggle_vector_skip", use_container_width=True):
                    st.session_state.vector_results_expanded_state = not st.session_state.vector_results_expanded_state in [True]
                    st.rerun()
            query_terms_for_vec_highlight = highlight.get_query_terms_for_highlight(st.session_state.executed_semantic_query_for_highlight, search_type="vector")
            num_to_expand = st.session_state.engine.initially_expanded_results_count
            for i, (chunk_doc, score) in enumerate(st.session_state.vector_search_results): # ã‚¹ãƒ©ã‚¤ã‚¹ã‚’å‰Šé™¤ã—å…¨ä»¶è¡¨ç¤º
                source_full_path = chunk_doc.metadata.get("source", "N/A")
                source_filename = Path(source_full_path).name
                page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
                page_num_info = f", Page: {page_num_str}" if page_num_str != "N/A" and page_num_str.isdigit() else ""
                highlighted_content_vec = highlight.highlight_text(chunk_doc.page_content, query_terms_for_vec_highlight, default_color="#E1BEE7", search_type="vector")

                # --- expandedãƒ­ã‚¸ãƒƒã‚¯ ---
                is_expanded = False
                if st.session_state.vector_results_expanded_state is True: is_expanded = True
                elif st.session_state.vector_results_expanded_state is False: is_expanded = False
                else: is_expanded = (i < num_to_expand)

                with st.expander(f"{i+1}. {source_filename}{page_num_info} (AIé¡ä¼¼åº¦ã‚¹ã‚³ã‚¢: {score:.4f})", expanded=is_expanded):
                    st.markdown(highlighted_content_vec, unsafe_allow_html=True)
            active_search_results_exist = True

        if active_search_results_exist:
            st.markdown("---")

    # 3. ANDæ¤œç´¢ã®ã¿ã®çµæœ (ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒãªãã€ã‚¹ã‚­ãƒƒãƒ—ã‚‚ã•ã‚Œã¦ã„ãªã„å ´åˆ)
    elif st.session_state.and_search_results:
        header_cols_and = st.columns([0.8, 0.2])
        
        # ä»¶æ•°è¡¨ç¤ºã®ãƒ­ã‚¸ãƒƒã‚¯: ãƒ¡ã‚¿æƒ…å ±ã‚’è¦‹ã¦ "+" ã‚’ã¤ã‘ã‚‹ã‹åˆ¤æ–­
        hit_count_str = f"{len(st.session_state.and_search_results)}"
        if st.session_state.search_result_meta.get("and_has_more"):
            st.caption(f"â€» è¡¨ç¤ºä¸Šé™ï¼ˆ{hit_count_str}ä»¶ï¼‰ã«é”ã—ãŸãŸã‚ã€ä¸€éƒ¨ã®çµæœã¯è¡¨ç¤ºã•ã‚Œã¾ã›ã‚“ã€‚")
            hit_count_str += "+"

        with header_cols_and[0]:
            st.markdown(f"#### <span style='background-color:#C8E6C9; color:black; padding:2px 6px; border-radius:4px;'>å®Œå…¨ä¸€è‡´</span>ï¼š {hit_count_str}ä»¶ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ç®‡æ‰€ï¼‰", unsafe_allow_html=True)
        with header_cols_and[1]:
            if 'and_results_expanded_state' not in st.session_state:
                st.session_state.and_results_expanded_state = None # åˆæœŸçŠ¶æ…‹: None, å…¨å±•é–‹: True, å…¨é–‰ã˜ã‚‹: False
            button_label_and = "ã™ã¹ã¦å±•é–‹" if st.session_state.and_results_expanded_state in [None, False] else "ã™ã¹ã¦é–‰ã˜ã‚‹"
            if st.button(button_label_and, key="toggle_and", use_container_width=True):
                st.session_state.and_results_expanded_state = not st.session_state.and_results_expanded_state in [True]
                st.rerun()

        query_terms_for_and_highlight = highlight.get_query_terms_for_highlight(st.session_state.executed_and_query_for_highlight, search_type="and")
        num_to_expand = st.session_state.engine.initially_expanded_results_count

        for i, chunk_doc in enumerate(st.session_state.and_search_results):
            source_full_path = chunk_doc.metadata.get("source", "N/A")
            source_filename = Path(source_full_path).name
            page_num_str = str(chunk_doc.metadata.get("page", "N/A"))
            page_num_info = f", Page: {page_num_str}" if page_num_str != "N/A" and page_num_str.isdigit() else ""
            highlighted_content_and = highlight.highlight_text(chunk_doc.page_content, query_terms_for_and_highlight, default_color="#C8E6C9", search_type="and")

            # --- expandedãƒ­ã‚¸ãƒƒã‚¯ ---
            is_expanded = False
            if st.session_state.and_results_expanded_state is True:
                is_expanded = True
            elif st.session_state.and_results_expanded_state is False:
                is_expanded = False
            else: # åˆæœŸçŠ¶æ…‹
                is_expanded = (i < num_to_expand)

            with st.expander(f"{i+1}. {source_filename}{page_num_info} (å®Œå…¨ä¸€è‡´)", expanded=is_expanded):
                st.markdown(highlighted_content_and, unsafe_allow_html=True)
        active_search_results_exist = True
        st.markdown("---")

    # 4. æ¤œç´¢æœªå®Ÿè¡Œã¾ãŸã¯çµæœãªã—ã®å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ (å¤‰æ›´ãªã—)
    if not any_query_executed:
        if not st.session_state.engine.get_loaded_files_info():
            documents_folder_name = st.session_state.engine.config['paths']['documents_folder']
            st.info(f"æ¤œç´¢å¯¾è±¡ã®æ–‡çŒ®ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n`{documents_folder_name}` ãƒ•ã‚©ãƒ«ãƒ€ã«ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿½åŠ ã—ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.info("å·¦ãƒ‘ãƒãƒ«ã®æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰æ¤œç´¢ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    elif any_query_executed and not active_search_results_exist:
        if st.session_state.search_was_cancelled:
            st.warning("æ¤œç´¢å‡¦ç†ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
        else:
            st.info("æ¤œç´¢æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")